<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Tutorial – Your Name - Data Science Portfolio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-f245066ca199b7326ac6b360085ddf3a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Your Name - Data Science Portfolio</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./about.html"> 
<span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="./tutorial.html" aria-current="page"> 
<span class="menu-text">Tutorial</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projects" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projects</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projects">    
        <li>
    <a class="dropdown-item" href="./projects/index.html">
 <span class="dropdown-text">All Projects</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li>
    <a class="dropdown-item" href="./projects/eda.html">
 <span class="dropdown-text">Exploratory Data Analysis</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./projects/data-acquisition.html">
 <span class="dropdown-text">Data Acquisition</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./projects/final-project.html">
 <span class="dropdown-text">Final Project</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/vaoikun"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://linkedin.com/in/vance-williams-"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#naive-bayes-classifiers-tutorial" id="toc-naive-bayes-classifiers-tutorial" class="nav-link active" data-scroll-target="#naive-bayes-classifiers-tutorial">Naive Bayes Classifiers Tutorial</a>
  <ul class="collapse">
  <li><a href="#headline" id="toc-headline" class="nav-link" data-scroll-target="#headline">Headline　</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#how-does-it-work" id="toc-how-does-it-work" class="nav-link" data-scroll-target="#how-does-it-work">How does it work?</a></li>
  <li><a href="#spam-problem" id="toc-spam-problem" class="nav-link" data-scroll-target="#spam-problem">Spam Problem</a></li>
  </ul></li>
  <li><a href="#body" id="toc-body" class="nav-link" data-scroll-target="#body">Body</a>
  <ul class="collapse">
  <li><a href="#naive-bayes-class" id="toc-naive-bayes-class" class="nav-link" data-scroll-target="#naive-bayes-class">Naive Bayes Class</a></li>
  </ul></li>
  <li><a href="#cta" id="toc-cta" class="nav-link" data-scroll-target="#cta">CTA</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Tutorial</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><a href="https://vaoikun.github.io/">Home</a> <img src="Spam.jpeg" alt="Description" width="150" style="float:right; margin-left:12px;"></p>
<section id="naive-bayes-classifiers-tutorial" class="level1">
<h1>Naive Bayes Classifiers Tutorial</h1>
<section id="headline" class="level2">
<h2 class="anchored" data-anchor-id="headline">Headline　</h2>
<p>Naïve Bayes classifiers are a family of machine learning classification methods that use Bayes’ theorem to probabilistically categorize data.<br>
They are called naïve because they assume independence between the features. The main idea is to use Bayes’ theorem to determine the probability that a certain data point belongs in a certain class, given the features of that data. Despite what the name may suggest, the naïve Bayes classifier is not a Bayesian method, as it is based on likelihood rather than Bayesian inference.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<section id="how-does-it-work" class="level3">
<h3 class="anchored" data-anchor-id="how-does-it-work">How does it work?</h3>
<p>Given the feature vector of a piece of data we want to classify, we want to know which of all the classes is most likely. Essentially, we want to answer the following question:</p>
<p><span class="math display">\[
\arg\max_{k \in K} P(C = k \mid \mathbf{x})
\]</span></p>
<p>where <span class="math inline">\(C\)</span> is the random variable representing the class of data. Using Bayes’ Theorem, we can reformulate this problem into something that is actually computable.</p>
<p>For any <span class="math inline">\(k \in K\)</span>,</p>
<p><span class="math display">\[
P(C = k \mid \mathbf{x}) = \frac{P(C = k)\,P(\mathbf{x} \mid C = k)}{P(\mathbf{x})}.
\]</span></p>
<p>After many lines of math, we get:</p>
<p><span class="math display">\[
\arg\max_{k \in K} P(C = k \mid \mathbf{x}) =
\arg\max_{k \in K} P(C = k)\prod_{i=1}^{n} P(x_i \mid C = k).
\]</span></p>
<hr>
</section>
<section id="spam-problem" class="level3">
<h3 class="anchored" data-anchor-id="spam-problem">Spam Problem</h3>
<p>A spam filter is just a special case of a classifier with two classes: spam and not spam (often called <em>ham</em>). Spam filtering is a situation where naïve Bayes classifiers perform relatively well.</p>
<p>We will use the SMS spam dataset from<br>
<a href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset">Kaggle SMS Spam Collection</a>.</p>
<p>After the data is cleaned by converting to lowercase and removing all punctuation, we are ready to start the classification.</p>
<p>Data is expected to look something like,</p>
<table class="caption-top table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="odd">
<td>ham</td>
<td>go until jurong point crazy available only in…</td>
</tr>
<tr class="even">
<td>spam</td>
<td>free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to…</td>
</tr>
<tr class="odd">
<td>ham</td>
<td>nah i dont think he goes to usf he lives around here though…</td>
</tr>
<tr class="even">
<td>spam</td>
<td>freemsg hey there darling its been 3 weeks now and no word back…</td>
</tr>
</tbody>
</table>
<hr>
</section>
</section>
<section id="body" class="level2">
<h2 class="anchored" data-anchor-id="body">Body</h2>
<section id="naive-bayes-class" class="level3">
<h3 class="anchored" data-anchor-id="naive-bayes-class">Naive Bayes Class</h3>
<p>We first create a Python class called <code>NaiveBayesFilter</code> with a constructor:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NaiveBayesFilter(ClassifierMixin):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">    A Naive Bayes Classifier that sorts messages into spam or ham.</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_prob <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_prob <span class="op">=</span> <span class="va">None</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_probs <span class="op">=</span> {}</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_probs <span class="op">=</span> {}</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>We then create a method called fit that compute <span class="math inline">\(P(C = \text{Spam}), P(C = \text{Ham})\)</span> and <span class="math inline">\(P(x_i|C)\)</span> to fit the model,</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Compute the values P(C=Ham), P(C=Spam), and P(x_i|C) to fit the model.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">            X (pd.Series): training data</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">            y (pd.Series): training labels</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_prob <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> <span class="st">"ham"</span>) <span class="op">/</span> N</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_prob <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> <span class="st">"spam"</span>) <span class="op">/</span> N</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tokenization</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> X.astype(<span class="bu">str</span>).<span class="bu">str</span>.split() <span class="co"># Split at white spaces</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>        spam_tokens <span class="op">=</span> [w <span class="cf">for</span> msg <span class="kw">in</span> tokens[y <span class="op">==</span> <span class="st">"spam"</span>] <span class="cf">for</span> w <span class="kw">in</span> msg]</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>        ham_tokens  <span class="op">=</span> [w <span class="cf">for</span> msg <span class="kw">in</span> tokens[y <span class="op">==</span> <span class="st">"ham"</span>]  <span class="cf">for</span> w <span class="kw">in</span> msg]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>        spam_counts <span class="op">=</span> Counter(spam_tokens)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>        ham_counts  <span class="op">=</span> Counter(ham_tokens)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        vocab <span class="op">=</span> <span class="bu">set</span>(spam_counts) <span class="op">|</span> <span class="bu">set</span>(ham_counts)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        V <span class="op">=</span> <span class="bu">len</span>(vocab)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Total number of word occurrences in each class</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>        total_spam_words <span class="op">=</span> <span class="bu">sum</span>(spam_counts.values())</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>        total_ham_words  <span class="op">=</span> <span class="bu">sum</span>(ham_counts.values())</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_probs <span class="op">=</span> {}</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_probs <span class="op">=</span> {}</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> w <span class="kw">in</span> vocab:</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.spam_probs[w] <span class="op">=</span> (spam_counts.get(w, <span class="dv">0</span>) <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> (total_spam_words <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ham_probs[w]  <span class="op">=</span> (ham_counts.get(w, <span class="dv">0</span>)  <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> (total_ham_words  <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>We can see that <code>self.ham_probs['out']</code> will give the value for <span class="math inline">\(P(x_i = '\text{out}' \mid C = \text{ham})\)</span>,</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example model trained on the first 300 data points</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> NaiveBayesFilter()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>nb.fit(X[:<span class="dv">300</span>], y[:<span class="dv">300</span>])</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Check spam and ham probabilities of 'out'</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>nb.ham_probs[<span class="st">'out'</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="fl">0.003147128245476003</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>nb.spam_probs[<span class="st">'out'</span>]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="fl">0.004166666666666667</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Now that we have trained our model, we can predict the class of a message by calculating</p>
<p><span class="math display">\[
P(C = k) \Pi^n_{i=1} P(x_i \mid C=k)
\]</span></p>
<p>for each class <span class="math display">\[k\]</span> . Directly computing this probability as a product can lead to an issue: underflow. If <span class="math inline">\(\mathbf{x}\)</span> is a particularly long message, then, since we are multiplying lots of numbers between 0 and 1, it is possible for the computed probability to underflow, or become too small to be machine representable with ordinary floating-point numbers. In this case the computed probability becomes 0. This is particularly problematic because if underflow happens for a sample for one class, it will likely also happen for all of the other classes, making such samples impossible to classify. To avoid this issue, we will work with the logarithm of the probability.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_proba(<span class="va">self</span>, X):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Find ln(P(C=k,x)) for each x in X and for each class.</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">            X (pd.Series)(N,): messages to classify</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">            (ndarray)(N,2): Log probability each message is ham or spam.</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">                Column 0 is ham, column 1 is spam.</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        msgs <span class="op">=</span> X.astype(<span class="bu">str</span>).values</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(msgs)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>        <span class="co"># log priors</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        log_ham_prior <span class="op">=</span> np.log(<span class="va">self</span>.ham_prob)</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        log_spam_prior <span class="op">=</span> np.log(<span class="va">self</span>.spam_prob)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        log_unseen <span class="op">=</span> np.log(<span class="fl">0.5</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> np.zeros((N, <span class="dv">2</span>), dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, msg <span class="kw">in</span> <span class="bu">enumerate</span>(msgs):</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            log_ham <span class="op">=</span> log_ham_prior</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            log_spam <span class="op">=</span> log_spam_prior</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># tokenization</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> w <span class="kw">in</span> msg.split():</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>                log_ham <span class="op">+=</span> np.log(<span class="va">self</span>.ham_probs.get(w, <span class="fl">0.5</span>))</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>                log_spam <span class="op">+=</span> np.log(<span class="va">self</span>.spam_probs.get(w, <span class="fl">0.5</span>))</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            out[i, <span class="dv">0</span>] <span class="op">=</span> log_ham</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            out[i, <span class="dv">1</span>] <span class="op">=</span> log_spam</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This will produce something like,</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>nb.predict_proba(X[<span class="dv">800</span>:<span class="dv">805</span>])</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>array([[ <span class="op">-</span><span class="fl">30.8951931</span> ,  <span class="op">-</span><span class="fl">35.42406687</span>],</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">108.85464069</span>,  <span class="op">-</span><span class="fl">91.70332157</span>],</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>       [ <span class="op">-</span><span class="fl">74.65014875</span>,  <span class="op">-</span><span class="fl">88.71184709</span>],</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">164.94297917</span>, <span class="op">-</span><span class="fl">133.8497405</span> ],</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">127.17743715</span>, <span class="op">-</span><span class="fl">101.32098062</span>]])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>Finally, we will implement the method <code>predict()</code> that makes predicted classification,</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">        Predict the labels of each row in X, using self.predict_proba().</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">        The label will be a string that is either 'spam' or 'ham'.</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">            X (pd.Series)(N,): messages to classify</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">            (ndarray)(N,): label for each message</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        logj <span class="op">=</span> <span class="va">self</span>.predict_proba(X)</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> np.where(logj[:, <span class="dv">1</span>] <span class="op">&gt;</span> logj[:, <span class="dv">0</span>], <span class="st">"spam"</span>, <span class="st">"ham"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> preds</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>We can now test our spam filter. We will use the sklearn’s train_test_split function with the default parameters to split the data into training and test sets. Train a NaiveBayesFilter on the train set, and have it predict the labels of each message in the test set.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.Message</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df.Label</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> NaiveBayesFilter()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>nb.fit(X_train, y_train)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> nb.predict(X_test)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># spam correctly identified</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>spam_mask <span class="op">=</span> (y_test.to_numpy() <span class="op">==</span> <span class="st">"spam"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>spam_correct <span class="op">=</span> np.mean(y_pred[spam_mask] <span class="op">==</span> <span class="st">"spam"</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ham incorrectly identified</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>ham_mask <span class="op">=</span> (y_test.to_numpy() <span class="op">==</span> <span class="st">"ham"</span>)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>ham_incorrect <span class="op">=</span> np.mean(y_pred[ham_mask] <span class="op">==</span> <span class="st">"spam"</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Spam correctly identified:"</span>, spam_correct)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Ham incorrectly identified:"</span>, ham_incorrect)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>This will yield,</p>
<pre><code>Spam correctly identified: np.float64(0.9513513513513514)
Ham incorrectly identified: np.float64(0.012417218543046357)</code></pre>
</section>
</section>
<section id="cta" class="level2">
<h2 class="anchored" data-anchor-id="cta">CTA</h2>
<p>While naïve Bayes classifiers are most easily seen as applicable in cases where the features have, ostensibly, well-defined probability distributions, they are applicable in many other cases. In this tutorial, we will apply them to the problem of spam filtering. While it is generally a bad idea to assume independence, naïve Bayes classifiers can still be very effective, even when we are confident that features are not independent.</p>
<p>This is just one of many implementations of the naïve Bayes Classifier. Try implementing your own naïve Bayes Classifier in your machine and try using a different dataset! You can find similar datasets in websites like <a href="https://archive.ics.uci.edu/dataset/228/sms+spam+collection">UCI Machine Learning Repository</a> and <a href="https://ieee-dataport.org/documents/sms-spam-dataset">IEEE DataPort</a> for free.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Tutorial"</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Home</span><span class="co">](https://vaoikun.github.io/)</span>  <span class="dt">&lt;</span><span class="kw">img</span><span class="ot"> src</span><span class="op">=</span><span class="st">"Spam.jpeg"</span><span class="ot"> alt</span><span class="op">=</span><span class="st">"Description"</span><span class="ot"> width</span><span class="op">=</span><span class="st">"150"</span><span class="ot"> style</span><span class="op">=</span><span class="st">"float:right; margin-left:12px;"</span><span class="dt">&gt;</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="fu"># Naive Bayes Classifiers Tutorial</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Headline　 </span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>Naïve Bayes classifiers are a family of machine learning classification methods that use Bayes’ theorem to probabilistically categorize data.  </span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>They are called naïve because they assume independence between the features. The main idea is to use Bayes’ theorem to determine the probability that a certain data point belongs in a certain class, given the features of that data. Despite what the name may suggest, the naïve Bayes classifier is not a Bayesian method, as it is based on likelihood rather than Bayesian inference.</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="fu">### How does it work?</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>Given the feature vector of a piece of data we want to classify, we want to know which of all the classes is most likely. Essentially, we want to answer the following question:</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>\arg\max_{k \in K} P(C = k \mid \mathbf{x})</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>where $C$ is the random variable representing the class of data. Using Bayes’ Theorem, we can reformulate this problem into something that is actually computable.</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>For any $k \in K$,</span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>P(C = k \mid \mathbf{x}) = \frac{P(C = k)\,P(\mathbf{x} \mid C = k)}{P(\mathbf{x})}.</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>After many lines of math, we get:</span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>\arg\max_{k \in K} P(C = k \mid \mathbf{x}) = </span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>\arg\max_{k \in K} P(C = k)\prod_{i=1}^{n} P(x_i \mid C = k).</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a><span class="fu">### Spam Problem</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>A spam filter is just a special case of a classifier with two classes: spam and not spam (often called *ham*). Spam filtering is a situation where naïve Bayes classifiers perform relatively well.</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>We will use the SMS spam dataset from  </span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Kaggle SMS Spam Collection</span><span class="co">](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)</span>.</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>After the data is cleaned by converting to lowercase and removing all punctuation, we are ready to start the classification.</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>Data is expected to look something like,</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span>   <span class="pp">|</span>   <span class="pp">|</span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a><span class="pp">|---|---|</span></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> ham <span class="pp">|</span> go until jurong point crazy available only in... <span class="pp">|</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> spam <span class="pp">|</span> free entry in 2 a wkly comp to win fa cup final tkts 21st may 2005 text fa to... <span class="pp">|</span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> ham <span class="pp">|</span> nah i dont think he goes to usf he lives around here though... <span class="pp">|</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> spam <span class="pp">|</span> freemsg hey there darling its been 3 weeks now and no word back...<span class="pp">|</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a><span class="fu">## Body</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a><span class="fu">### Naive Bayes Class</span></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>We first create a Python class called <span class="in">`NaiveBayesFilter`</span> with a constructor:</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NaiveBayesFilter(ClassifierMixin):</span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a><span class="co">    A Naive Bayes Classifier that sorts messages into spam or ham.</span></span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_prob <span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_prob <span class="op">=</span> <span class="va">None</span></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_probs <span class="op">=</span> {}</span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_probs <span class="op">=</span> {}</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>We then create a method called fit that compute </span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>$P(C = \text{Spam}), P(C = \text{Ham})$ and $P(x_i|C)$</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>to fit the model,</span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a><span class="co">        Compute the values P(C=Ham), P(C=Spam), and P(x_i|C) to fit the model.</span></span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a><span class="co">            X (pd.Series): training data</span></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a><span class="co">            y (pd.Series): training labels</span></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_prob <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> <span class="st">"ham"</span>) <span class="op">/</span> N</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_prob <span class="op">=</span> <span class="bu">sum</span>(y <span class="op">==</span> <span class="st">"spam"</span>) <span class="op">/</span> N</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Tokenization</span></span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>        tokens <span class="op">=</span> X.astype(<span class="bu">str</span>).<span class="bu">str</span>.split() <span class="co"># Split at white spaces</span></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>        spam_tokens <span class="op">=</span> [w <span class="cf">for</span> msg <span class="kw">in</span> tokens[y <span class="op">==</span> <span class="st">"spam"</span>] <span class="cf">for</span> w <span class="kw">in</span> msg]</span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>        ham_tokens  <span class="op">=</span> [w <span class="cf">for</span> msg <span class="kw">in</span> tokens[y <span class="op">==</span> <span class="st">"ham"</span>]  <span class="cf">for</span> w <span class="kw">in</span> msg]</span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>        spam_counts <span class="op">=</span> Counter(spam_tokens)</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>        ham_counts  <span class="op">=</span> Counter(ham_tokens)</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>        vocab <span class="op">=</span> <span class="bu">set</span>(spam_counts) <span class="op">|</span> <span class="bu">set</span>(ham_counts)</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>        V <span class="op">=</span> <span class="bu">len</span>(vocab)</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Total number of word occurrences in each class</span></span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>        total_spam_words <span class="op">=</span> <span class="bu">sum</span>(spam_counts.values())</span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>        total_ham_words  <span class="op">=</span> <span class="bu">sum</span>(ham_counts.values())</span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.spam_probs <span class="op">=</span> {}</span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.ham_probs <span class="op">=</span> {}</span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> w <span class="kw">in</span> vocab:</span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.spam_probs[w] <span class="op">=</span> (spam_counts.get(w, <span class="dv">0</span>) <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> (total_spam_words <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.ham_probs[w]  <span class="op">=</span> (ham_counts.get(w, <span class="dv">0</span>)  <span class="op">+</span> <span class="dv">1</span>) <span class="op">/</span> (total_ham_words  <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>We can see that ```self.ham_probs<span class="co">[</span><span class="ot">'out'</span><span class="co">]</span>``` will give the value for $P(x_i = '\text{out}' \mid C = \text{ham})$,</span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a><span class="co"># Example model trained on the first 300 data points</span></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> NaiveBayesFilter()</span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>nb.fit(X[:<span class="dv">300</span>], y[:<span class="dv">300</span>])</span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a><span class="co"># Check spam and ham probabilities of 'out'</span></span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a>nb.ham_probs[<span class="st">'out'</span>]</span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a><span class="fl">0.003147128245476003</span></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a>nb.spam_probs[<span class="st">'out'</span>]</span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a><span class="fl">0.004166666666666667</span></span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a>Now that we have trained our model, we can predict the class of a message by calculating</span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a>P(C = k) \Pi^n_{i=1} P(x_i \mid C=k) </span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a>for each class $$k$$ .</span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a>Directly computing this probability as a product can lead to an issue: underflow. If $\mathbf{x}$ is a particularly long message, then, since we are multiplying lots of numbers between 0 and 1, it is possible for the computed probability to underflow, or become too small to be machine representable with ordinary floating-point numbers. In this case the computed probability becomes 0. This is particularly problematic because if underflow happens for a sample for one class, it will likely also happen for all of the other classes, making such samples impossible to classify. To avoid this issue, we will work with the logarithm of the probability. </span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict_proba(<span class="va">self</span>, X):</span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a><span class="co">        Find ln(P(C=k,x)) for each x in X and for each class.</span></span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a><span class="co">            X (pd.Series)(N,): messages to classify</span></span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a><span class="co">            (ndarray)(N,2): Log probability each message is ham or spam.</span></span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a><span class="co">                Column 0 is ham, column 1 is spam.</span></span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a>        msgs <span class="op">=</span> X.astype(<span class="bu">str</span>).values</span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a>        N <span class="op">=</span> <span class="bu">len</span>(msgs)</span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a>        <span class="co"># log priors</span></span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a>        log_ham_prior <span class="op">=</span> np.log(<span class="va">self</span>.ham_prob)</span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a>        log_spam_prior <span class="op">=</span> np.log(<span class="va">self</span>.spam_prob)</span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a>        log_unseen <span class="op">=</span> np.log(<span class="fl">0.5</span>)</span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> np.zeros((N, <span class="dv">2</span>), dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, msg <span class="kw">in</span> <span class="bu">enumerate</span>(msgs):</span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a>            log_ham <span class="op">=</span> log_ham_prior</span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a>            log_spam <span class="op">=</span> log_spam_prior</span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a>            <span class="co"># tokenization</span></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> w <span class="kw">in</span> msg.split():</span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a>                log_ham <span class="op">+=</span> np.log(<span class="va">self</span>.ham_probs.get(w, <span class="fl">0.5</span>))</span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a>                log_spam <span class="op">+=</span> np.log(<span class="va">self</span>.spam_probs.get(w, <span class="fl">0.5</span>))</span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-168"><a href="#cb9-168" aria-hidden="true" tabindex="-1"></a>            out[i, <span class="dv">0</span>] <span class="op">=</span> log_ham</span>
<span id="cb9-169"><a href="#cb9-169" aria-hidden="true" tabindex="-1"></a>            out[i, <span class="dv">1</span>] <span class="op">=</span> log_spam</span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a>This will produce something like,</span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a>nb.predict_proba(X[<span class="dv">800</span>:<span class="dv">805</span>])</span>
<span id="cb9-178"><a href="#cb9-178" aria-hidden="true" tabindex="-1"></a>array([[ <span class="op">-</span><span class="fl">30.8951931</span> ,  <span class="op">-</span><span class="fl">35.42406687</span>],</span>
<span id="cb9-179"><a href="#cb9-179" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">108.85464069</span>,  <span class="op">-</span><span class="fl">91.70332157</span>],</span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a>       [ <span class="op">-</span><span class="fl">74.65014875</span>,  <span class="op">-</span><span class="fl">88.71184709</span>],</span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">164.94297917</span>, <span class="op">-</span><span class="fl">133.8497405</span> ],</span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>       [<span class="op">-</span><span class="fl">127.17743715</span>, <span class="op">-</span><span class="fl">101.32098062</span>]])</span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-184"><a href="#cb9-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-185"><a href="#cb9-185" aria-hidden="true" tabindex="-1"></a>Finally, we will implement the method ```predict()``` that makes predicted classification,</span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''</span></span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a><span class="co">        Predict the labels of each row in X, using self.predict_proba().</span></span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a><span class="co">        The label will be a string that is either 'spam' or 'ham'.</span></span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a><span class="co">        Parameters:</span></span>
<span id="cb9-194"><a href="#cb9-194" aria-hidden="true" tabindex="-1"></a><span class="co">            X (pd.Series)(N,): messages to classify</span></span>
<span id="cb9-195"><a href="#cb9-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-196"><a href="#cb9-196" aria-hidden="true" tabindex="-1"></a><span class="co">        Return:</span></span>
<span id="cb9-197"><a href="#cb9-197" aria-hidden="true" tabindex="-1"></a><span class="co">            (ndarray)(N,): label for each message</span></span>
<span id="cb9-198"><a href="#cb9-198" aria-hidden="true" tabindex="-1"></a><span class="co">        '''</span></span>
<span id="cb9-199"><a href="#cb9-199" aria-hidden="true" tabindex="-1"></a>        logj <span class="op">=</span> <span class="va">self</span>.predict_proba(X)</span>
<span id="cb9-200"><a href="#cb9-200" aria-hidden="true" tabindex="-1"></a>        preds <span class="op">=</span> np.where(logj[:, <span class="dv">1</span>] <span class="op">&gt;</span> logj[:, <span class="dv">0</span>], <span class="st">"spam"</span>, <span class="st">"ham"</span>)</span>
<span id="cb9-201"><a href="#cb9-201" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> preds</span>
<span id="cb9-202"><a href="#cb9-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-203"><a href="#cb9-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-204"><a href="#cb9-204" aria-hidden="true" tabindex="-1"></a>We can now test our spam filter. We will use the sklearn’s train_test_split function with the default parameters to split the data into training and test sets. Train a NaiveBayesFilter on the train set, and have it predict the labels of each message in the test set. </span>
<span id="cb9-205"><a href="#cb9-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-206"><a href="#cb9-206" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb9-207"><a href="#cb9-207" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.Message</span>
<span id="cb9-208"><a href="#cb9-208" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df.Label</span>
<span id="cb9-209"><a href="#cb9-209" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb9-210"><a href="#cb9-210" aria-hidden="true" tabindex="-1"></a>nb <span class="op">=</span> NaiveBayesFilter()</span>
<span id="cb9-211"><a href="#cb9-211" aria-hidden="true" tabindex="-1"></a>nb.fit(X_train, y_train)</span>
<span id="cb9-212"><a href="#cb9-212" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> nb.predict(X_test)</span>
<span id="cb9-213"><a href="#cb9-213" aria-hidden="true" tabindex="-1"></a><span class="co"># spam correctly identified</span></span>
<span id="cb9-214"><a href="#cb9-214" aria-hidden="true" tabindex="-1"></a>spam_mask <span class="op">=</span> (y_test.to_numpy() <span class="op">==</span> <span class="st">"spam"</span>)</span>
<span id="cb9-215"><a href="#cb9-215" aria-hidden="true" tabindex="-1"></a>spam_correct <span class="op">=</span> np.mean(y_pred[spam_mask] <span class="op">==</span> <span class="st">"spam"</span>)</span>
<span id="cb9-216"><a href="#cb9-216" aria-hidden="true" tabindex="-1"></a><span class="co"># ham incorrectly identified</span></span>
<span id="cb9-217"><a href="#cb9-217" aria-hidden="true" tabindex="-1"></a>ham_mask <span class="op">=</span> (y_test.to_numpy() <span class="op">==</span> <span class="st">"ham"</span>)</span>
<span id="cb9-218"><a href="#cb9-218" aria-hidden="true" tabindex="-1"></a>ham_incorrect <span class="op">=</span> np.mean(y_pred[ham_mask] <span class="op">==</span> <span class="st">"spam"</span>)</span>
<span id="cb9-219"><a href="#cb9-219" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Spam correctly identified:"</span>, spam_correct)</span>
<span id="cb9-220"><a href="#cb9-220" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Ham incorrectly identified:"</span>, ham_incorrect)</span>
<span id="cb9-221"><a href="#cb9-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-222"><a href="#cb9-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-223"><a href="#cb9-223" aria-hidden="true" tabindex="-1"></a>This will yield,</span>
<span id="cb9-224"><a href="#cb9-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-225"><a href="#cb9-225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-226"><a href="#cb9-226" aria-hidden="true" tabindex="-1"></a><span class="in">Spam correctly identified: np.float64(0.9513513513513514)</span></span>
<span id="cb9-227"><a href="#cb9-227" aria-hidden="true" tabindex="-1"></a><span class="in">Ham incorrectly identified: np.float64(0.012417218543046357)</span></span>
<span id="cb9-228"><a href="#cb9-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-229"><a href="#cb9-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-230"><a href="#cb9-230" aria-hidden="true" tabindex="-1"></a><span class="fu">## CTA</span></span>
<span id="cb9-231"><a href="#cb9-231" aria-hidden="true" tabindex="-1"></a>While naïve Bayes classifiers are most easily seen as applicable in cases where the features have, ostensibly, well-defined probability distributions, they are applicable in many other cases. In this tutorial, we will apply them to the problem of spam filtering. While it is generally a bad idea to assume independence, naïve Bayes classifiers can still be very effective, even when we are confident that features are not independent.</span>
<span id="cb9-232"><a href="#cb9-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-233"><a href="#cb9-233" aria-hidden="true" tabindex="-1"></a>This is just one of many implementations of the naïve Bayes Classifier. Try implementing your own naïve Bayes Classifier in your machine and try using a different dataset!</span>
<span id="cb9-234"><a href="#cb9-234" aria-hidden="true" tabindex="-1"></a>You can find similar datasets in websites like <span class="co">[</span><span class="ot">UCI Machine Learning Repository</span><span class="co">](https://archive.ics.uci.edu/dataset/228/sms+spam+collection)</span> and <span class="co">[</span><span class="ot">IEEE DataPort</span><span class="co">](https://ieee-dataport.org/documents/sms-spam-dataset)</span> for free. </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




</body></html>